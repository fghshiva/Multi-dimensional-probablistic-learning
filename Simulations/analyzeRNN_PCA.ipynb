{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/flatiron/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import scipy as sc\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.python.framework import ops\n",
    "import statsmodels.formula.api as smf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from sklearn.metrics import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_val, W0_in_val, W0_rec_val, W0_out_val, C_da_val, b_rec_val = pickle.load( \n",
    "    open( \"./files/RNN_0.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------\n",
    "# Probability of reward\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# mdprl probability matrix\n",
    "prob_mdprl                  = np.zeros((3,3,3))\n",
    "prob_mdprl[:,:,0]           = ([0.92, 0.75, 0.43], [0.50, 0.50, 0.50], [0.57, 0.25, 0.08])\n",
    "prob_mdprl[:,:,1]           = ([0.16, 0.75, 0.98], [0.50, 0.50, 0.50], [0.02, 0.25, 0.84])\n",
    "prob_mdprl[:,:,2]           = ([0.92, 0.75, 0.43], [0.50, 0.50, 0.50], [0.57, 0.25, 0.08])\n",
    "\n",
    "# random probability matrix\n",
    "prob_rand                   = np.random.uniform(0, 1, size=(3, 3, 3))\n",
    "\n",
    "# generalizable probability matrix\n",
    "prob_gen                    = np.zeros((3, 3, 3))\n",
    "prob_gen[:,:,0]             = 0.9\n",
    "prob_gen[:,:,1]             = 0.5\n",
    "prob_gen[:,:,2]             = 0.1\n",
    "\n",
    "# 0.5 probability matrix\n",
    "prob_noinf                  = 0.5*np.ones((3, 3, 3))\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# trial timing parameters\n",
    "#-----------------------------------------------------------------------------------------\n",
    "s              = 1\n",
    "ms             = 10**-3 \n",
    "dt             = 20*ms\n",
    "tauX           = 100*ms\n",
    "alphaX         = dt/tauX\n",
    "T              = np.linspace(-0.5*s, 1.5*s, 1+2*int(s/dt))\n",
    "T_s            = (T>0.0*s) & (T<=1.2*s)    # when stimuli is present on the screen\n",
    "T_da           = (T>1.0*s) & (T<=1.2*s)    # when dopamine is released\n",
    "T_ch           = (T>0.7*s) & (T<=1.0*s)    # when choice is read (only used for making the target)\n",
    "T_sch          = 1.5*(T<0.0*s) + T_ch      # when choice is read (used for training the network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! /usr/bin/env python\n",
    "\"\"\"\n",
    "Generates input\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Generates indices of active input populations of size 27*Nrep (trials)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def generateinput(N_s, prob_index, T_s, T_da, T_ch):\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    # initialization\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    index_pttrn  = np.zeros((3,3,3))\n",
    "    index_shp    = np.zeros((3,3,3))\n",
    "    index_clr    = np.zeros((3,3,3))\n",
    "    \n",
    "    index_shppttrn  = np.zeros((3,3,3))\n",
    "    index_pttrnclr  = np.zeros((3,3,3))\n",
    "    index_shpclr    = np.zeros((3,3,3))\n",
    "\n",
    "    filter_s     = T_s.astype(int)\n",
    "    filter_da    = T_da.astype(int).reshape((-1,1))\n",
    "    filter_ch    = T_ch.astype(int).reshape((-1,1))\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    # indexing features\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    for d in range(3):\n",
    "        index_shp[:,:,d]     = np.matrix([[0, 1, 2], [0, 1, 2], [0, 1, 2]]) \n",
    "        index_pttrn[:,:,d]   = np.matrix([[0, 0, 0], [1, 1, 1], [2, 2, 2]]) \n",
    "        index_clr[:,:,d]     = np.matrix([[1, 1, 1], [1, 1, 1], [1, 1, 1]])*d \n",
    "        \n",
    "        index_shppttrn[:,:,d]= index_shp[:,:,d]*3   + index_pttrn[:,:,d]\n",
    "        index_pttrnclr[:,:,d]= index_pttrn[:,:,d]*3 + index_clr[:,:,d]\n",
    "        index_shpclr[:,:,d]  = index_shp[:,:,d]*3   + index_clr[:,:,d]\n",
    "\n",
    "    index_shp       = index_shp.flatten().astype(int)\n",
    "    index_pttrn     = index_pttrn.flatten().astype(int)\n",
    "    index_clr       = index_clr.flatten().astype(int)\n",
    "    index_shppttrn  = index_shppttrn.flatten().astype(int)\n",
    "    index_pttrnclr  = index_pttrnclr.flatten().astype(int)\n",
    "    index_shpclr    = index_shpclr.flatten().astype(int)\n",
    "    prob_index      = prob_index.flatten()\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    # generate population activity\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    index_s      = np.repeat(np.arange(0,27,1),N_s)\n",
    "    pop_o        = np.zeros((len(T), len(index_s), 27))\n",
    "    pop_s        = np.zeros((len(T), len(index_s), 63))\n",
    "    ch_s         = np.zeros((len(T), 1))\n",
    "    rw_s         = np.zeros((len(T), len(index_s)))\n",
    "    for n in range(len(index_s)):\n",
    "        pop_s[:, n, index_shp[index_s[n]]]          = filter_s*1\n",
    "        pop_s[:, n, 3+index_pttrn[index_s[n]]]      = filter_s*1\n",
    "        pop_s[:, n, 6+index_clr[index_s[n]]]        = filter_s*1\n",
    "        \n",
    "        pop_s[:, n, 9+index_shppttrn[index_s[n]]]   = filter_s*1\n",
    "        pop_s[:, n, 18+index_pttrnclr[index_s[n]]]  = filter_s*1\n",
    "        pop_s[:, n, 27+index_shpclr[index_s[n]]]    = filter_s*1\n",
    "        \n",
    "        pop_s[:, n, 36+index_s[n]]                  = filter_s*1\n",
    "        pop_o[:, n, index_s[n]]                     = filter_s*1\n",
    "\n",
    "    R            = np.random.binomial(1, prob_index[index_s]) \n",
    "    ch_s         = filter_ch*prob_index[index_s]\n",
    "    DA_s         = filter_da*R - filter_da*(1-R)\n",
    "    prob_s       = prob_index[index_s]\n",
    "    \n",
    "    # output\n",
    "    return DA_s, ch_s, pop_s, pop_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------\n",
    "# Network parameters\n",
    "#-----------------------------------------------------------------------------------------\n",
    "N_s            = 10\n",
    "idxNin         = np.arange(0,63,1) # np.arange(0,9,1), np.arange(9,36,1), np.arange(36,63,1)\n",
    "Nin            = len(idxNin)\n",
    "Nrec           = 120\n",
    "Nout           = 1\n",
    "batch_size     = 27*N_s\n",
    "init_stddev    = 0.01\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# Inhibitory/Excitatory\n",
    "#-----------------------------------------------------------------------------------------\n",
    "pE = 0.8 \n",
    "Nexc = int(pE*Nrec)\n",
    "Ninh = Nrec - Nexc\n",
    "idx = range(Nrec)\n",
    "EXC = idx[:Nexc]\n",
    "INH = idx[Nexc:]\n",
    "\n",
    "F_rec       = np.ones((1,Nrec))\n",
    "extinh      = np.ones((1,Nrec))\n",
    "F_rec[:,INH] *= -1\n",
    "extinh[:,INH] *= 0\n",
    "\n",
    "F_out       = np.zeros((Nrec,Nout))\n",
    "F_out[EXC]  = 1\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# Dopamine modulation\n",
    "#-----------------------------------------------------------------------------------------\n",
    "mda_in0  = np.zeros((Nin, Nrec))\n",
    "mda_in0[:, idx[:int(Nexc/2)]] = 1\n",
    "mda_in0[:, idx[-int(Ninh/2):]] = 1\n",
    "mda_rec0 = np.zeros((Nrec, Nrec))\n",
    "mda_rec0[:, idx[int(Nexc/4):int(3*Nexc/4)]] = 1\n",
    "mda_rec0[:, idx[-int(3*Ninh/4):-int(Ninh/4)]] = 1\n",
    "\n",
    "mda_lsn0 = np.ones((Nrec,Nrec))                      # for lesioning the RNN\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# Network noise\n",
    "#-----------------------------------------------------------------------------------------\n",
    "var_in         = (0.001**2)\n",
    "var_rec        = (0.015**2)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# Input noise\n",
    "#-----------------------------------------------------------------------------------------\n",
    "var_in         = 2*tauX/dt*var_in\n",
    "if np.any(var_in > 0):\n",
    "    noise_in           = np.sqrt(var_in)*np.random.normal(size=(len(T)*batch_size, Nin))\n",
    "else:\n",
    "    noise_in           = np.zeros((len(T)*batch_size, Nin))\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# Recurrent noise\n",
    "#-----------------------------------------------------------------------------------------\n",
    "var_rec = 2/dt*var_rec\n",
    "if np.any(var_rec > 0):\n",
    "    noise_rec          = np.sqrt(var_rec)*np.random.normal(size=(len(T)*batch_size, Nrec))\n",
    "    noise_rectest      = np.sqrt(var_rec)*np.random.normal(size=(len(T)*27, Nrec))\n",
    "else:\n",
    "    noise_rec          = np.zeros((len(T)*batch_size, Nrec))\n",
    "    noise_rectest      = np.zeros((len(T)*27, Nrec))\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# Weight initialization \n",
    "#---------------------------------------------------------------------------------\n",
    "x_init         = tf.constant_initializer(x0_val)\n",
    "Win_init       = tf.constant_initializer(W0_in_val)\n",
    "Wrec_init      = tf.constant_initializer(W0_rec_val)\n",
    "Wout_init      = tf.constant_initializer(W0_out_val)\n",
    "brec_init      = tf.constant_initializer(b_rec_val)\n",
    "bout_init      = tf.constant_initializer(0)\n",
    "C_dainit       = tf.constant_initializer(C_da_val)\n",
    "mda_ininit     = tf.constant_initializer(mda_in0)\n",
    "mda_recinit    = tf.constant_initializer(mda_rec0)\n",
    "mda_lsninit    = tf.constant_initializer(mda_lsn0)\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# Activation functions\n",
    "#---------------------------------------------------------------------------------\n",
    "f_hidden       = tf.nn.relu \n",
    "f_output       = tf.nn.relu\n",
    "f_weight       = tf.nn.relu     # to impose positivity on weights\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# Optimization parameters\n",
    "#-----------------------------------------------------------------------------------------\n",
    "optimizer      = tf.train.AdamOptimizer\n",
    "lr             = 0.001\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# Etc.\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_relu(x):\n",
    "    return (abs(x) + x) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------\n",
    "# Network structure\n",
    "#---------------------------------------------------------------------------------\n",
    "ops.reset_default_graph()\n",
    "# len(T)*batch_size\n",
    "T_schRNN       = tf.placeholder(tf.float32, (None,1))         # to calculate the output loss\n",
    "T_daRNN        = tf.placeholder(tf.float32, (None,1))         # to implement reward learning\n",
    "T_sRNN         = tf.placeholder(tf.float32, (None,1))         # to calculate loss of middle layer acitivity\n",
    "T0_RNN         = tf.placeholder(tf.float32, (None,1))         # to implement reseting of x to x0\n",
    "\n",
    "u_RNN          = tf.placeholder(tf.float32, (None,Nin))\n",
    "nrec_RNN       = tf.placeholder(tf.float32, (None,Nrec))\n",
    "x_RNN          = tf.placeholder(tf.float32, (None,Nrec))\n",
    "z_RNN          = tf.placeholder(tf.float32, (None,Nout))\n",
    "\n",
    "W_in           = tf.placeholder(tf.float32, (None,Nin, Nrec))\n",
    "W_rec          = tf.placeholder(tf.float32, (None,Nrec,Nrec))\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# Initial values\n",
    "#---------------------------------------------------------------------------------\n",
    "x0_RNN         = tf.get_variable('x0_RNN', shape=(1,   Nrec), initializer=x_init,    trainable=True)\n",
    "W0_in          = tf.get_variable('W0_in',  shape=(Nin, Nrec), initializer=Win_init,  trainable=True)\n",
    "W0_rec         = tf.get_variable('W0_rec', shape=(Nrec,Nrec), initializer=Wrec_init, trainable=True)\n",
    "W0_out         = tf.get_variable('W0_out', shape=(Nrec,Nout), initializer=Wout_init, trainable=True)         \n",
    "\n",
    "b_rec          = tf.get_variable('b_rec',  shape=(1,   Nrec), initializer=brec_init, trainable=True)\n",
    "b_out          = tf.get_variable('b_out',  shape=(1,   Nout), initializer=bout_init, trainable=False)\n",
    "\n",
    "C_da           = tf.get_variable('C_da',   shape=(6,1), initializer=C_dainit, trainable=True)\n",
    "mda_in         = tf.get_variable('mda_in', shape=(Nin, Nrec), initializer=mda_ininit,  trainable=False)\n",
    "mda_rec        = tf.get_variable('mda_rec',shape=(Nrec,Nrec), initializer=mda_recinit, trainable=False)\n",
    "mda_lsn        = tf.get_variable('mda_lsn',shape=(Nrec,Nrec), initializer=mda_lsninit, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(x, u):\n",
    "    x_RNN, W_in, W_rec = tf.split(x,[1, Nin, Nrec],0)\n",
    "    u_in, n_rec, T0, Tda = u\n",
    "    W_in       = f_weight(W_in)\n",
    "    W_rec      = f_weight(W_rec)\n",
    "    W_rec      = tf.multiply(W_rec, mda_lsn)\n",
    "    W_rec      = tf.multiply(W_rec, tf.ones(Nrec)-tf.eye(Nrec))\n",
    "    \n",
    "    r_RNN      = f_hidden(x_RNN)\n",
    "    rF_RNN     = tf.multiply(r_RNN, F_rec)\n",
    "    \n",
    "    x_RNN      = (1-T0)*((1 - alphaX)*x_RNN                                # Leak\n",
    "                          + alphaX*(tf.matmul(rF_RNN, W_rec)               # Recurrent\n",
    "                          + b_rec                                          # Bias\n",
    "                          + tf.matmul(tf.reshape(u_in, (1, -1)), W_in)     # Input\n",
    "                          + tf.reshape(n_rec, (1,-1)))                     # Recurrent noise\n",
    "                          ) + T0*x0_RNN\n",
    "    \n",
    "    deltaW_in  = dt*( (Tda*C_da[0])*(tf.matmul(tf.reshape(u_in, (-1, 1)), tf.ones((1,Nrec))))\n",
    "                    + (Tda*C_da[1])*(tf.matmul(tf.ones((Nin,1)), tf.reshape(r_RNN, (1, -1))))\n",
    "                    + (Tda*C_da[2])*(tf.matmul(tf.reshape(u_in, (-1, 1)), tf.reshape(r_RNN, (1, -1)))))\n",
    "    W_in       = W_in + tf.multiply(deltaW_in, mda_in)\n",
    "    \n",
    "    deltaW_rec = dt*( (Tda*C_da[3])*(tf.matmul(tf.reshape(r_RNN, (-1, 1)), tf.ones((1,Nrec))))\n",
    "                    + (Tda*C_da[4])*(tf.matmul(tf.ones((Nrec,1)), tf.reshape(r_RNN, (1, -1))))\n",
    "                    + (Tda*C_da[5])*(tf.matmul(tf.reshape(r_RNN, (-1, 1)), tf.reshape(r_RNN, (1, -1)))))\n",
    "    W_rec      = W_rec + tf.multiply(deltaW_rec, mda_rec)\n",
    "    \n",
    "    W_in       = f_weight(W_in)\n",
    "    W_rec      = f_weight(W_rec)\n",
    "    W_rec      = tf.multiply(W_rec, tf.ones(Nrec)-tf.eye(Nrec))\n",
    "    return tf.concat([x_RNN, W_in, W_rec],0)\n",
    "\n",
    "x              = tf.scan(rnn, (u_RNN, nrec_RNN, T0_RNN, T_daRNN), \n",
    "                                    initializer=tf.concat([x0_RNN, W0_in, W0_rec], 0))\n",
    "x_RNN, W_in, W_rec = tf.split(x,[1, Nin, Nrec],1)\n",
    "x_RNN          = tf.reshape(x_RNN , [-1, Nrec])\n",
    "r              = f_hidden(x_RNN)\n",
    "WF_out         = tf.multiply(f_weight(W0_out), F_out)\n",
    "z              = f_output(tf.matmul(r, WF_out) + b_out)\n",
    "lossZ          = tf.reduce_mean((z_RNN - tf.multiply(z,T_schRNN))**2)\n",
    "lossR          = tf.reduce_mean(r**2)\n",
    "loss           = (lossZ) + 0.001*lossR\n",
    "\n",
    "train_op       = optimizer(learning_rate=lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_schbatch     = np.tile(T_sch,batch_size).reshape((-1,1))\n",
    "T_chbatch      = np.tile(T_ch,batch_size).reshape((-1,1))\n",
    "T_dabatch      = np.tile(T_da,batch_size).reshape((-1,1))\n",
    "\n",
    "T0             = (T==-0.5*s).astype(int)\n",
    "T0_batch       = np.tile(T0,batch_size).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrep            = 100\n",
    "nbouts          = N_s\n",
    "sdshffle = np.array(range(27*N_s))\n",
    "sdshffle = sdshffle.reshape((27,N_s)).T.flatten()\n",
    "\n",
    "bouts = np.linspace(0, N_s*len(T)*27, nbouts+1).astype(int)\n",
    "r_vals = np.empty((N_s*len(T)*27,Nrec,nrep))\n",
    "for rep in range(nrep):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        prob_index     = prob_mdprl\n",
    "        DA_s, ch_s, pop_s, pop_o    = generateinput(N_s, prob_index, T_s, T_da, T_ch)\n",
    "        pop_s          = pop_s[:,:,idxNin]\n",
    "        pop_oRNN       = np.concatenate([pop_o[:,t,:] for t in sdshffle], axis=0) \n",
    "        pop_sRNN       = np.concatenate([pop_s[:,t,:] for t in sdshffle], axis=0)\n",
    "        DA_sRNN        = np.concatenate([DA_s[:,t] for t in sdshffle], axis=0).reshape((-1,1))\n",
    "        ch_sRNN        = np.concatenate([ch_s[:,t] for t in sdshffle], axis=0).reshape((-1,1))\n",
    "\n",
    "        z_val, r_val, x_val, W_in_val, W_rec_val, W0_out_val, C_da_val = sess.run([\n",
    "                z, r, x_RNN, W_in, W_rec, W0_out, C_da], \n",
    "                                            feed_dict={ u_RNN: pop_sRNN, nrec_RNN: noise_rec,  \n",
    "                                                        z_RNN: ch_sRNN,    T0_RNN: T0_batch,  \n",
    "                                                     T_schRNN: T_schbatch,T_daRNN: DA_sRNN})\n",
    "        \n",
    "        r_vals[:,:,rep] = r_val.reshape((-1,Nrec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.io.savemat('./files/r_vals_PCAtime.mat', {'r_vals': r_vals})\n",
    "sc.io.savemat('./files/r_vals_PCA.mat', {'r_vals': r_vals[np.where(T_chbatch)[0],:,:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
